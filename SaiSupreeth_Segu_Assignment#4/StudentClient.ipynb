{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackjackAgent():\n",
    "    \n",
    "#     blev = BlackjackEnv(natural=False)\n",
    "#     p1 = Player(player_name='C1')\n",
    "#     blev.add_player(p1)\n",
    "    def reset_env(self):\n",
    "        #print('here')\n",
    "        pkev = BlackjackEnv(natural=False)\n",
    "        p1 = Player(player_name='C1')\n",
    "        p2 = Player(player_name='P1')\n",
    "        self.p1 = p1\n",
    "        pkev.add_player(p1)\n",
    "        #print(p1)\n",
    "        return pkev\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.env = self.reset_env()\n",
    "        self.Q = np.zeros((34,2))\n",
    "        \n",
    "    def epsilon_greed(self, epsilon, s):\n",
    "        #ac = [self.env.get_valid_actions(self.me)]\n",
    "        ac = [0,1]\n",
    "        if np.random.rand()<epsilon:\n",
    "            return np.random.randint(len(ac))\n",
    "        else:\n",
    "            #print(\"agd : \",s)\n",
    "            #print(\"fld:\",s['player_sum_card'])\n",
    "            #print(\"agd : \",ac)\n",
    "            return np.argmax(self.Q[s['player_sum_card']][ac])\n",
    "    \n",
    "    def train(self,**params):\n",
    "        \n",
    "        # parameters\n",
    "        gamma = params.pop('gamma', 0.99)\n",
    "        alpha = params.pop('alpha', 0.1)\n",
    "        epsilon = params.pop('epsilon', 0.1)\n",
    "        maxiter = params.pop('maxiter', 1000) \n",
    "        sarsa = params.pop('sarsa',False)\n",
    "        edecay = params.pop('edecay',None)\n",
    "        import time\n",
    "        rtrace = []\n",
    "        for i in range(maxiter):\n",
    "            if i == 20000:\n",
    "                #print(self.Q)\n",
    "                time.sleep(5)\n",
    "            self.env = self.reset_env()\n",
    "            if edecay is not None:\n",
    "                epsilon = max(0.1,epsilon*edecay)\n",
    "            #print('*'*50,i+1,'*'*50)\n",
    "            #Check if you have enough money left in the account to bet, if not break and start a new game\n",
    "            valid_bet_flag = self.env.get_valid_bet_amount(self.p1.player_name)\n",
    "            if valid_bet_flag['is_round_done']:\n",
    "                #print(\"You are out of money ! Will go to next game !!\")\n",
    "                break\n",
    "            bet_amount = valid_bet_flag['valid_bet_amount']\n",
    "        \n",
    "            #Get the observations i.e state and use it to decide how much you want to bet\n",
    "            round_obs = self.env.init_round(self.p1.player_name)\n",
    "            #print(\"Initial state: {}\".format(round_obs))  \n",
    "        \n",
    "            # If you have just $1 left in the bank, you have no choice but to bet that amount \n",
    "            # and hopefully leave it to the fate for your agent to win and continue playing or just\n",
    "            # start a new game\n",
    "            if len(bet_amount) == 1 and bet_amount[0] == 1:\n",
    "                #print(\"You can only bet 1. So betting only 1.\")\n",
    "                random_bet = 1\n",
    "            else:\n",
    "                random_bet = np.random.choice(bet_amount)\n",
    "                #print(\"Random Init Bet: {}\".format(random_bet))\n",
    "            self.env.bet_money(self.p1.player_name, random_bet)\n",
    "        \n",
    "            random_action = np.random.randint(0, 2)\n",
    "            #print(\"Action taken: {}\".format(random_action))\n",
    "            \n",
    "            #Use the selected action to actually take the action in env by calling step\n",
    "            res = self.env.step(self.p1.player_name, random_action)\n",
    "            #print(\"State after 1st action: {}\".format(round_obs))\n",
    "            #rewards = []\n",
    "            #res = {'is_round_done':False}\n",
    "            while not res['is_round_done']:\n",
    "                #print('-'*50)\n",
    "                #print(self.env.get_current_state())\n",
    "                f = 0\n",
    "                s = self.env.get_player_obs(self.p1.player_name)\n",
    "                a = self.epsilon_greed(epsilon,s)\n",
    "                #va = [self.env.get_valid_actions(self.me)]\n",
    "                va = [0,1]\n",
    "                res = self.env.step(self.p1.player_name, a)\n",
    "                #res = self.env.player_play(self.me,va[a])\n",
    "                #end = res[-1]\n",
    "                r = res['reward']\n",
    "                rewards.append(r)\n",
    "                #print(\"1:\",rewards)\n",
    "                if not res['is_round_done']:\n",
    "                    f = 1\n",
    "                    s1 = self.env.get_player_obs(self.p1.player_name)\n",
    "                    a1 = self.epsilon_greed(epsilon,s1)\n",
    "                    #va1 = self.env.get_valid_actions(self.me)\n",
    "                    res = self.env.step(self.p1.player_name, a1)\n",
    "                    r1 = res['reward']\n",
    "                    rewards.append(r1)\n",
    "                    #print(\"2:\",rewards)\n",
    "                s2 = self.env.get_player_obs(self.p1.player_name)\n",
    "                #print(\"S => \",s)\n",
    "                #print(\"S2 => \",s2)\n",
    "#                 print(\"s -> \" ,s)\n",
    "#                 print(\"s1 -> \",s1)\n",
    "                    # if f:\n",
    "                    # self.Q[s1,a1]\n",
    "                #print(\"va=> \",va)\n",
    "                #print(\"a=> \",a)\n",
    "                self.Q[s['player_sum_card']][a] += alpha*(r + gamma*np.max(self.Q[s2['player_sum_card']][va]) - \n",
    "                                      self.Q[s['player_sum_card']][a])  \n",
    "                \n",
    "            self.env = self.reset_env()\n",
    "            rtrace.append(np.sum(rewards))\n",
    "            #print(rtrace)\n",
    "        return rtrace,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import os\n",
    "import subprocess\n",
    "import ast\n",
    "import numpy as np\n",
    "#import BlackjackAgent\n",
    "player = 'supreeth' #enter unique name for your game\n",
    "s = socket.socket()\n",
    "host = '10.216.25.34' # change ip addres to ip adress of your computer or use 'localhost' to practice\n",
    "port = 9999\n",
    "\n",
    "s.connect((host, port))\n",
    "\n",
    "while True:\n",
    "    data = s.recv(1024)\n",
    "    if data.decode(\"utf-8\") == 'send':\n",
    "        s.send(str.encode( player))\n",
    "        client_response = str(s.recv(20480), \"utf-8\")\n",
    "        print(client_response, end=\"\")\n",
    "        break\n",
    "while True:\n",
    "    data = s.recv(1024)\n",
    "    if data.decode(\"utf-8\") == 'sendbet':\n",
    "        ro=str(s.recv(20480), \"utf-8\")\n",
    "        ro=ast.literal_eval(ro)\n",
    "        print(ro)\n",
    "# The above observation are stored in dict format. To access specific variables use syntax as \n",
    "# ro['state']['player_info']['player_total_balance']\n",
    "# send whichever variable information stored in ro to your agent to help make the decision\n",
    "#### Look at the above observations stored in variable ro as dictionary and store bet amount in variable bet#####\n",
    "        bet=np.random.choice(10)\n",
    "        s.send(str.encode( str(bet)))\n",
    "        \n",
    "    if data.decode(\"utf-8\") == 'sendaction':\n",
    "        ro=str(s.recv(20480), \"utf-8\")\n",
    "        ro=ast.literal_eval(ro)\n",
    "        print(ro)\n",
    "        #follow same procedure as abov to send observations to your agent\n",
    "        ###### Look at the above observations and action in variable action#####\n",
    "        \n",
    "        action = np.random.randint(0, 2)\n",
    "        #proplayer1 = BlackjackAgent()\n",
    "        #proplayer1.train(maxiter = 120,edecay=0.99,epsilon=0.2,gamma=0.8)\n",
    "        #action = np.argmax(self.Q[s['player_sum_card']][valid_ac])\n",
    "        #print(\"action \",action)\n",
    "        s.send(str.encode( str(action)))\n",
    "    if data.decode(\"utf-8\") == 'gameover':\n",
    "        print(\"Game over wait for others to play and wait for results\")\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
